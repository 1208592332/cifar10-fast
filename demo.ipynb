{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.precision = 4\n",
    "pd.options.display.width = 180\n",
    "\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# utils\n",
    "#####################\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self):\n",
    "        self.times = [time.time()]\n",
    "    def __call__(self):\n",
    "        self.times.append(time.time())\n",
    "        return self.times[-1] - self.times[-2]\n",
    "    def total_time(self):\n",
    "        return self.times[-1] - self.times[0]\n",
    "    \n",
    "def curry(func):\n",
    "    keyword_args = [p.name for p in signature(func).parameters.values() if p.default is not p.empty]\n",
    "    n = namedtuple(func.__name__, keyword_args)\n",
    "    n.__call__ = lambda self, x: func(x, **self._asdict())\n",
    "    return n\n",
    "\n",
    "localtime = lambda: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())\n",
    "\n",
    "def show(logs):\n",
    "    clear_output(wait=True)\n",
    "    df = pd.DataFrame(logs, columns=logs[0].keys())\n",
    "    display(HTML(df.to_html(index=False)))\n",
    "\n",
    "def warmup_cudnn(model, batch_size):\n",
    "    batch = {\n",
    "        'input': torch.Tensor(np.random.rand(batch_size,3,32,32)).cuda().half(), \n",
    "        'target': torch.LongTensor(np.random.randint(0,10,batch_size)).cuda()\n",
    "    }\n",
    "    model.train(True)\n",
    "    o = model(batch)\n",
    "    o['loss'].backward()\n",
    "    model.zero_grad()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    \n",
    "#####################\n",
    "## data preprocessing\n",
    "#####################\n",
    "\n",
    "def normalise(x, mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616)):\n",
    "    x, mean, std = [np.array(a, np.float32) for a in (x, mean, std)]\n",
    "    x -= mean*255\n",
    "    x *= 1.0/(255*std)\n",
    "    return x\n",
    "\n",
    "def pad(x, border=4):\n",
    "    return np.pad(x, [(0, 0), (border, border), (border, border), (0, 0)], mode='reflect')\n",
    "\n",
    "def transpose(x, source='NHWC', target='NCHW'):\n",
    "    return x.transpose([source.index(d) for d in target]) \n",
    "\n",
    "\n",
    "#####################\n",
    "## data augmentation\n",
    "#####################\n",
    "\n",
    "def _random_window(x, h, w):\n",
    "    C,H,W = x.shape\n",
    "    y0, x0 = np.random.randint(H+1-h), np.random.randint(W+1-w)\n",
    "    return x[:,y0:y0+h,x0:x0+w]\n",
    "\n",
    "@curry\n",
    "def random_crop(x, h=32, w=32):\n",
    "    return _random_window(x, h, w)\n",
    "\n",
    "def flip_lr(x):\n",
    "    x = x[:, :, ::-1] if np.random.choice((True, False)) else x \n",
    "    return x.copy()\n",
    "\n",
    "@curry\n",
    "def cutout(x, h=8, w=8, prob=1.0):\n",
    "    if np.random.uniform() < prob:\n",
    "        _random_window(x, h, w).fill(0.0)\n",
    "    return x\n",
    "\n",
    "class Transform():\n",
    "    def __init__(self, dataset, transforms):\n",
    "        self.dataset, self.transforms = dataset, transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "           \n",
    "    def __getitem__(self, index):\n",
    "        data, labels = self.dataset[index]\n",
    "        for f in self.transforms:\n",
    "            data = f(data)\n",
    "        return data, labels\n",
    "\n",
    "#####################\n",
    "## data loading\n",
    "#####################\n",
    "\n",
    "class Batches():\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=batch_size, num_workers=1, pin_memory=True, shuffle=shuffle\n",
    "        )\n",
    "    def __iter__(self): return ({'input': x.to(device).half(), 'target': y.to(device).long()} for (x,y) in self.dataloader)\n",
    "    def __len__(self): return len(self.dataloader)\n",
    "\n",
    "\n",
    "#####################\n",
    "## torch stuff\n",
    "#####################\n",
    "\n",
    "class Mul():\n",
    "    def __init__(self, weight): self.weight = weight\n",
    "    def __call__(self, x): return x*self.weight\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), x.size(1))\n",
    "\n",
    "class Add(nn.Module):\n",
    "    def forward(self, x, y): return x + y \n",
    "    \n",
    "class Correct(nn.Module):\n",
    "    def forward(self, classifier, target):\n",
    "        return classifier.max(dim = 1)[1] == target\n",
    "\n",
    "class TorchGraph(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        self.graph = [node if len(node) == 3 else (node[0], node[1], [net[idx-1][0]]) for idx, node in enumerate(net)]\n",
    "        super().__init__()\n",
    "        for (n, v, _) in self.graph: \n",
    "            setattr(self, n, v)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.cache = dict(inputs)\n",
    "        for (n, _, i) in self.graph:\n",
    "            self.cache[n] = getattr(self, n)(*[self.cache[x] for x in i])\n",
    "        return self.cache\n",
    "    \n",
    "    def half(self):\n",
    "        for module in self.children():\n",
    "            if type(module) is not nn.BatchNorm2d:\n",
    "                module.half()    \n",
    "        return self\n",
    "    \n",
    "pool = nn.AvgPool2d(2)\n",
    "relu = nn.ReLU(inplace=True)\n",
    "bn = nn.BatchNorm2d\n",
    "\n",
    "def bn(num_channels, bias_init=-0.25, weight_init=0.5):\n",
    "    #note weight initialisation scale is largely irrelevant to the forward computation\n",
    "    #but changes the effective scale and thus learning rate of biases\n",
    "    m = nn.BatchNorm2d(num_channels)\n",
    "    if bias_init is not None:\n",
    "        m.bias.data.fill_(bias_init)\n",
    "    m.weight.data.fill_(weight_init)\n",
    "    m.weight.requires_grad = False\n",
    "    return m\n",
    "\n",
    "def conv(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()  \n",
    "\n",
    "#####################\n",
    "## training\n",
    "#####################\n",
    "@curry\n",
    "def piecewise_linear(t, knots=(), vals=()):\n",
    "    return np.interp([t], knots, vals)[0]\n",
    "\n",
    "def nesterov(model, momentum=None, weight_decay=None):\n",
    "    return torch.optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=0.0,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        nesterov=True\n",
    "    )\n",
    "\n",
    "avg = lambda xs: np.mean(np.array(xs) if xs[0].shape is () else np.concatenate(xs), dtype=np.float)\n",
    "\n",
    "def train(model, epochs, lr_schedule, batch_size, optimizer, train_batches, test_batches):\n",
    "    logs = [] \n",
    "    out = widgets.Output()\n",
    "    print(f'Starting training at {localtime()}')\n",
    "    display(out)\n",
    "    t = Timer()\n",
    "    for epoch in range(epochs):\n",
    "        stats = {k: {'loss': [], 'correct': []} for k in ('train', 'test')}\n",
    "        model.train(True)\n",
    "        for i, batch in enumerate(train_batches):\n",
    "            lr = lr_schedule(epoch + (i+1)/len(train_batches))\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "            model.zero_grad()\n",
    "            output = model(batch)\n",
    "            for k,v in stats['train'].items():\n",
    "                v.append(to_numpy(output[k]))  \n",
    "            output['loss'].backward()\n",
    "            optimizer.step()\n",
    "        train_time = t()\n",
    "        model.train(False)\n",
    "        for i, batch in enumerate(test_batches):\n",
    "            output = model(batch)\n",
    "            for k,v in stats['test'].items():\n",
    "                v.append(to_numpy(output[k]))\n",
    "        test_time = t()\n",
    "        logs.append({\n",
    "           'epoch': epoch+1, 'lr': lr*batch_size, \n",
    "            'train time': train_time, 'train loss': avg(stats['train']['loss'])/batch_size, 'train acc': avg(stats['train']['correct']), \n",
    "            'test time': test_time, 'test loss': avg(stats['test']['loss'])/batch_size, 'test acc': avg(stats['test']['correct']),\n",
    "            'total time': t.total_time(), \n",
    "        })\n",
    "        with out:\n",
    "            show(logs)\n",
    "    print(f'Finished training at {localtime()}')\n",
    "    return logs\n",
    "\n",
    "\n",
    "#####################\n",
    "## network definition\n",
    "#####################\n",
    "\n",
    "def network(c=64, weight=0.25):\n",
    "    net = [\n",
    "        ('prep_conv', conv(3, c), ['input']),\n",
    "        ('prep_bn', bn(c)),\n",
    "        ('prep_relu', relu),\n",
    "\n",
    "        ('layer1_conv', conv(c, c*2)),\n",
    "        ('layer1_bn', bn(c*2)),\n",
    "        ('layer1_relu', relu),\n",
    "        ('layer1_pool', pool),\n",
    "        ('layer1_res1_conv', conv(c*2, c*2)),\n",
    "        ('layer1_res1_bn', bn(c*2)),\n",
    "        ('layer1_res1_relu', relu),\n",
    "        ('layer1_res2_conv', conv(c*2, c*2)),\n",
    "        ('layer1_res2_bn', bn(c*2)),\n",
    "        ('layer1_res2_relu', relu),\n",
    "        ('layer1_add', Add(), ['layer1_pool', 'layer1_res2_relu']),\n",
    "        \n",
    "        ('layer2_conv', conv(c*2, c*4)),\n",
    "        ('layer2_bn', bn(c*4)),\n",
    "        ('layer2_relu', relu),\n",
    "        ('layer2_pool', pool),\n",
    "\n",
    "        ('layer3_conv', conv(c*4, c*4)),\n",
    "        ('layer3_bn', bn(c*4)),\n",
    "        ('layer3_relu', relu),\n",
    "\n",
    "        ('layer4_conv', conv(c*4, c*8)),\n",
    "        ('layer4_bn', bn(c*8)),\n",
    "        ('layer4_relu', relu),\n",
    "\n",
    "        ('pool', nn.AdaptiveMaxPool2d(1)),\n",
    "        ('flatten', Flatten()),\n",
    "        ('classifier_fc', nn.Linear(c*8, 10, bias=True)),\n",
    "        ('classifier', Mul(weight)),\n",
    "\n",
    "        ('loss', nn.CrossEntropyLoss(size_average=False), ['classifier', 'target']),\n",
    "        ('correct', Correct(), ['classifier', 'target']),\n",
    "    ]\n",
    "    return TorchGraph(net).to(device).half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preprocessing training data\n",
      "Finished in 2.4 seconds\n",
      "Preprocessing test data\n",
      "Finished in 0.093 seconds\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data'\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
    "t = Timer()\n",
    "print('Preprocessing training data')\n",
    "train_set = list(zip(transpose(normalise(pad(train_set.train_data, 4))), train_set.train_labels))\n",
    "print(f'Finished in {t():.2} seconds')\n",
    "print('Preprocessing test data')\n",
    "test_set = list(zip(transpose(normalise(test_set.test_data)), test_set.test_labels))\n",
    "print(f'Finished in {t():.2} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up cudnn on a batch of random inputs\n",
      "Finished in 1.17 seconds\n",
      "Starting training at 2018-10-01 10:52:58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9064eb039d88451e979971d25979b9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training at 2018-10-01 10:54:26\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = piecewise_linear([0,6,25], [0, 0.1/128, 0])\n",
    "epochs = 25\n",
    "batch_size = 512\n",
    "\n",
    "train_batches = Batches(Transform(train_set, [random_crop(32, 32), flip_lr, cutout(8, 8, 1.0)]), batch_size, shuffle=True)\n",
    "test_batches = Batches(test_set, batch_size, shuffle=False)\n",
    "\n",
    "model = network()\n",
    "\n",
    "t = Timer()\n",
    "print('Warming up cudnn on a batch of random inputs')\n",
    "warmup_cudnn(network(), batch_size)\n",
    "print(f'Finished in {t():.3} seconds')\n",
    "\n",
    "logs = train(model, epochs, lr_schedule, batch_size, nesterov(model, momentum=0.9, weight_decay=batch_size*5e-4), train_batches, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
